{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeans_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "source": [
        "# Game Classification Model"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UID9RK1qDlVB",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_1kOEGDTws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eccc66bd-8b04-4d4f-faa1-b4b0d22df5c8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\")\n",
        "game_data = pd.read_csv('game_data.csv') #names = col_names if not in CSV\n",
        "# game_data.head() # See the first 5 rows"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_pPmK9GIKMz",
        "colab_type": "text"
      },
      "source": [
        "### clean and filter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WevSKogFEalU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dc31b65e-b7f5-4116-ec89-5790fdb604bc"
      },
      "source": [
        "# bgg_games = game_data[game_data['type'] == 'boardgame'] # no expansions\n",
        "bgg_games = game_data[game_data['year'] > 1980]\n",
        "# bgg_games = bgg_games[bgg_games['year'] > 1980]\n",
        "bgg_games = bgg_games[bgg_games['maxplayers'] <= 30]\n",
        "bgg_games = bgg_games[bgg_games['minplaytime'] <= 180] # 120 - 90th percentile\n",
        "bgg_games = bgg_games[bgg_games['maxplaytime'] <= 720]\n",
        "bgg_games = bgg_games[bgg_games['minage'] <= 21]\n",
        "bgg_games = bgg_games[bgg_games['playingtime'] >= 10]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cell for data exploration\n",
        "# bgg_games.columns"
      ]
    },
    {
      "source": [
        "### select cells potentially relevant to categories"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = bgg_games[['type', 'year', 'minplayers', 'maxplayers', 'playingtime',\n",
        "       'minplaytime', 'maxplaytime', 'minage', 'users_rated', 'avg_rating',\n",
        "       'bay_rating', 'owners', 'traders', 'wanters', 'wishers',\n",
        "       'total_comments', 'total_weights', 'complexity', 'categories',\n",
        "       'mechanics']]\n",
        "dtc_test = dtc_test[dtc_test['maxplayers'] >= dtc_test['minplayers']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for player diff potential and playtime "
      ]
    },
    {
      "source": [
        "#### convert mechanics and categories into lists with values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['categories'] = dtc_test['categories'].apply(lambda x: x.strip('][').split(', ') )\n",
        "dtc_test['mechanics'] = dtc_test['mechanics'].apply(lambda x: x.strip('][').split(', ') )"
      ]
    },
    {
      "source": [
        "#### count number of mechanics and categories for each game, make new columns"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_mechs = []\n",
        "num_cats = []\n",
        "for index, row in dtc_test.iterrows():\n",
        "    num_mechs.append(len(row['mechanics']))\n",
        "    num_cats.append(len(row['categories']))\n",
        "\n",
        "dtc_test['num_mechs'] = num_mechs\n",
        "dtc_test['num_cats'] = num_cats\n",
        "dtc_test['rating_diff'] = dtc_test.avg_rating - dtc_test.bay_rating\n",
        "dtc_test['player_diff'] = dtc_test.maxplayers - dtc_test.minplayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    15768.000000\n",
              "mean        60.613902\n",
              "std         57.030217\n",
              "min         10.000000\n",
              "25%         30.000000\n",
              "50%         45.000000\n",
              "75%         75.000000\n",
              "max        720.000000\n",
              "Name: playingtime, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# explore data\n",
        "dtc_test['playingtime'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30     3099\n",
              "60     2569\n",
              "45     1846\n",
              "20     1707\n",
              "90     1367\n",
              "       ... \n",
              "38        1\n",
              "23        1\n",
              "72        1\n",
              "39        1\n",
              "108       1\n",
              "Name: playingtime, Length: 61, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# data exploration\n",
        "dtc_test['playingtime'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# data exploration\n",
        "dtc_test.loc[dtc_test.playingtime < 10, 'playingtime'].count()\n",
        "\n",
        "# dtc_test['time_diff'] = dtc_test.maxplaytime - dtc_test.minplaytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_frame_list(df, target_column, output_type=str):\n",
        "    ''' \n",
        "    Accepts a column with list values and splits into several rows.\n",
        "\n",
        "    df: dataframe to split\n",
        "    target_column: the column containing the values to split\n",
        "    output_type: type of all outputs\n",
        "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
        "    The values in the other columns are duplicated across the newly divided rows.\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def split_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(s)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(split_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df\n",
        "\n",
        "def dupe_data_frame_list(df, target_column, output_type=list):\n",
        "    ''' \n",
        "    duplicate rows for each value in a list instead (for 'y_test' only)\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def dupe_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(split_row)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(dupe_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df"
      ]
    },
    {
      "source": [
        "#### split lists into multiple rows for decision tree"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TESTING: after data split for train/test portions?\n",
        "# dtc_test = split_data_frame_list(dtc_test, 'categories')\n",
        "dtc_test = split_data_frame_list(dtc_test, 'mechanics')"
      ]
    },
    {
      "source": [
        "#### get all desired cols and apply one-hot fix to categorical features"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for filtering cols\n",
        "desired_cols = ['minplayers','maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'avg_rating', 'bay_rating', 'complexity', 'categories', 'mechanics', 'num_mechs', 'num_cats', 'minage', 'rating_diff', 'player_diff']\n",
        "#desired_cols = ['year', 'minplayers', 'maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'minage', 'users_rated', 'avg_rating', 'bay_rating', 'owners', 'traders', 'wanters', 'wishers', 'total_comments', 'total_weights', 'complexity', 'categories', 'mechanics'] # leave out 'type'\n",
        "\n",
        "# make dummies and attach to frame for tree model\n",
        "tree_frame = dtc_test[desired_cols]\n",
        "mech_dummies = pd.get_dummies(tree_frame['mechanics'], prefix='mech', drop_first=True)\n",
        "tree_frame = pd.concat([tree_frame, mech_dummies], axis=1)"
      ]
    },
    {
      "source": [
        "#### filter out categorical columns for tree fitting"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of just desired features, now including one-hot cols and remove categorical cols\n",
        "features = list(tree_frame.columns)\n",
        "\n",
        "# remove either categorical cols or all cols\n",
        "features.remove('mechanics')\n",
        "# features.remove('categories')\n",
        "\n",
        "# for col in desired_cols:\n",
        "#     features.remove(col)\n",
        "# print(features)"
      ]
    },
    {
      "source": [
        "### Divide the data set\n",
        "#### split data into training portions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtered features with one-hot fixes for categorical columns\n",
        "# keep categories for now for splitting into rows\n",
        "X = tree_frame[features]\n",
        "\n",
        "# target variable\n",
        "y = tree_frame[['categories']]\n",
        "\n",
        "# Split method, 0.3 == 30% of data saved for testing, choosen randomly from set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "source": [
        "### split X_train, X_test, and y_train so model can \"learn\" different categories separately\n",
        "### keep y_test.categories intact for y_prediction comparisons"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done!\n"
          ]
        }
      ],
      "source": [
        "# split training and x_test by category\n",
        "X_train = split_data_frame_list(X_train, 'categories')\n",
        "X_test = split_data_frame_list(X_test, 'categories')\n",
        "y_train = split_data_frame_list(y_train, 'categories')\n",
        "\n",
        "# dupe instead of split for accuracy tests\n",
        "y_test = dupe_data_frame_list(y_test, 'categories')\n",
        "\n",
        "# remove categories from X for train/test\n",
        "features = list(X_train.columns)\n",
        "features.remove('categories')\n",
        "X_train = X_train[features]\n",
        "X_test = X_test[features]\n",
        "\n",
        "print('done!')"
      ]
    },
    {
      "source": [
        "### Train the model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q42-XPJjIyXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "94c92518-3ea7-48e3-999c-762159548e53"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "best_acc = 0\n",
        "for j in range(1, 20):\n",
        "    # Decision Tree classifer object\n",
        "    dtc = DecisionTreeClassifier(criterion=\"entropy\", splitter='best', max_depth=19+j)\n",
        "\n",
        "    # Train Decision Tree Classifer\n",
        "    dtc = dtc.fit(X_train,y_train)\n",
        "\n",
        "    # predictions by model for y\n",
        "    y_pred = dtc.predict(X_test)\n",
        "\n",
        "    # custom accuracy check\n",
        "    correct = 0\n",
        "    y_targets = y_test[\"categories\"].tolist() \n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] in y_targets[i]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtc)\n",
        "        best_acc = accuracy\n",
        "        print(\"depth: \", j)\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth:  1\n",
            "best acc:  0.8826976347751971\n",
            "depth:  5\n",
            "best acc:  0.8830438951630087\n",
            "depth:  7\n",
            "best acc:  0.8831238014063498\n",
            "depth:  11\n",
            "best acc:  0.8860004261666311\n",
            "depth:  24\n",
            "best acc:  0.8868527594289367\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-28-1e78ad197649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Train Decision Tree Classifer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdtc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# predictions by model for y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "source": [
        "# SAVE MODEL!! (and test accuracy of accuracy rating)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# swtich to model directory\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\models\")\n",
        "\n",
        "# create and save file\n",
        "joblib_file = \"dtc_all_9041.joblib\"  \n",
        "dump(best_dtc, joblib_file)\n",
        "\n",
        "# test load\n",
        "joblib_model = load(joblib_file)\n",
        "\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# custom accuracy check\n",
        "correct = 0\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] in y_targets[i]:\n",
        "        correct += 1\n",
        "\n",
        "print(\"Accuracy:\", correct / len(y_pred))"
      ]
    },
    {
      "source": [
        "### visualize training depths"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "max_depth = []\n",
        "acc_gini = []\n",
        "acc_entropy = []\n",
        "\n",
        "best_acc = correct / len(y_pred)\n",
        "best_dtc = dtc\n",
        "\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(1,36):\n",
        "    # testing entropy\n",
        "    dtree = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_entropy.append(accuracy)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # testing gini\n",
        "    dtree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_gini.append(accuracy)\n",
        "\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # track depth for values\n",
        "    max_depth.append(i)\n",
        "\n",
        "\n",
        "# data frame with tracked values to graph\n",
        "df = pd.DataFrame({'acc_gini':pd.Series(acc_gini), \n",
        "'acc_entropy':pd.Series(acc_entropy),\n",
        "'max_depth':pd.Series(max_depth)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib_file = \"dtc_8936.joblib\"  \n",
        "dump(best_dtc, joblib_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# graph folder\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\graphs\")\n",
        "\n",
        "#size \n",
        "sns.set(rc={'figure.figsize': (6, 6)})\n",
        "\n",
        "print(max_depth)\n",
        "# visualizing changes in parameters\n",
        "sns.lineplot(x='max_depth', y='acc_gini', data=df)\n",
        "sns.lineplot(x='max_depth', y='acc_entropy', data=df)\n",
        "plt.xlabel('max depth')\n",
        "plt.ylabel('accuracy')\n",
        "# plt.xlim(1,30)\n",
        "plt.savefig('gini vs entropy', bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "### Visualize training tree model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "# dot_data = StringIO()\n",
        "# # number of unique values in target col\n",
        "# class_names = list(tree_frame.categories.unique())\n",
        "\n",
        "# # use trained decision tree model, feature columns, and clases in target col\n",
        "# export_graphviz(dtc, out_file = dot_data, filled=True, rounded=True, special_characters=True,\n",
        "#                 feature_names = features,\n",
        "#                 class_names = class_names)\n",
        "\n",
        "# # creates image and then displays in Jupyter\n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# graph.write_png('game_classes.png')\n",
        "# Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}