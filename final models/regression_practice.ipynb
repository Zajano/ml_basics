{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeans_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "source": [
        "# Game Classification Model"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UID9RK1qDlVB",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_1kOEGDTws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eccc66bd-8b04-4d4f-faa1-b4b0d22df5c8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn import metrics\n",
        "\n",
        "# more models for testing\n",
        "from sklearn import model_selection\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.metrics import r2_score\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\")\n",
        "game_data = pd.read_csv('game_data.csv') #names = col_names if not in CSV\n",
        "# game_data.head() # See the first 5 rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_pPmK9GIKMz",
        "colab_type": "text"
      },
      "source": [
        "### clean and filter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WevSKogFEalU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dc31b65e-b7f5-4116-ec89-5790fdb604bc"
      },
      "source": [
        "# bgg_games = game_data[game_data['type'] == 'boardgame'] # no expansions\n",
        "bgg_games = game_data[game_data['year'] > 1980]\n",
        "# bgg_games = bgg_games[bgg_games['year'] > 1980]\n",
        "bgg_games = bgg_games[bgg_games['maxplayers'] <= 30]\n",
        "bgg_games = bgg_games[bgg_games['minplaytime'] <= 180] # 120 - 90th percentile\n",
        "bgg_games = bgg_games[bgg_games['maxplaytime'] <= 720]\n",
        "bgg_games = bgg_games[bgg_games['minage'] <= 21]\n",
        "bgg_games = bgg_games[bgg_games['playingtime'] >= 10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cell for data exploration\n",
        "# bgg_games.columns"
      ]
    },
    {
      "source": [
        "### select cells potentially relevant to rating (before community interaction)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = bgg_games[['type', 'minplayers', 'maxplayers', 'playingtime',\n",
        "       'minplaytime', 'maxplaytime', 'minage', 'avg_rating', 'mechanics',\n",
        "       'bay_rating', 'total_comments', 'total_weights', 'complexity', 'categories']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for player pool size\n",
        "dtc_test = dtc_test[dtc_test['maxplayers'] >= dtc_test['minplayers']]"
      ]
    },
    {
      "source": [
        "#### convert mechanics and categories into lists with values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test['categories'] = dtc_test['categories'].apply(lambda x: x.strip('][').split(', ') )\n",
        "dtc_test['mechanics'] = dtc_test['mechanics'].apply(lambda x: x.strip('][').split(', ') )"
      ]
    },
    {
      "source": [
        "#### count number of mechanics and categories for each game, make new columns"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_mechs = []\n",
        "num_cats = []\n",
        "for index, row in dtc_test.iterrows():\n",
        "    num_mechs.append(len(row['mechanics']))\n",
        "    num_cats.append(len(row['categories']))\n",
        "\n",
        "dtc_test['num_mechs'] = num_mechs\n",
        "dtc_test['num_cats'] = num_cats\n",
        "dtc_test['player_diff'] = dtc_test.maxplayers - dtc_test.minplayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# explore data\n",
        "dtc_test['playingtime'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data exploration\n",
        "dtc_test['playingtime'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data exploration\n",
        "dtc_test.loc[dtc_test.playingtime < 10, 'playingtime'].count()\n",
        "\n",
        "# dtc_test['time_diff'] = dtc_test.maxplaytime - dtc_test.minplaytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data_frame_list(df, target_column, output_type=str):\n",
        "    ''' \n",
        "    Accepts a column with list values and splits into several rows.\n",
        "\n",
        "    df: dataframe to split\n",
        "    target_column: the column containing the values to split\n",
        "    output_type: type of all outputs\n",
        "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
        "    The values in the other columns are duplicated across the newly divided rows.\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def split_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(s)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(split_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df\n",
        "\n",
        "def dupe_data_frame_list(df, target_column, output_type=list):\n",
        "    ''' \n",
        "    duplicate rows for each value in a list instead (for 'y_test' only)\n",
        "    '''\n",
        "    row_accumulator = []\n",
        "\n",
        "    def dupe_list_to_rows(row):\n",
        "        split_row = row[target_column]\n",
        "        if isinstance(split_row, list):\n",
        "          for s in split_row:\n",
        "              new_row = row.to_dict()\n",
        "              new_row[target_column] = output_type(split_row)\n",
        "              row_accumulator.append(new_row)\n",
        "        else:\n",
        "          new_row = row.to_dict()\n",
        "          new_row[target_column] = output_type(split_row)\n",
        "          row_accumulator.append(new_row)\n",
        "  \n",
        "    df.apply(dupe_list_to_rows, axis=1)\n",
        "    new_df = pd.DataFrame(row_accumulator)\n",
        "  \n",
        "    return new_df"
      ]
    },
    {
      "source": [
        "#### split lists into multiple rows for regression model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtc_test = split_data_frame_list(dtc_test, 'categories')\n",
        "dtc_test = split_data_frame_list(dtc_test, 'mechanics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(list(dtc_test.columns))"
      ]
    },
    {
      "source": [
        "#### get all desired cols and apply one-hot fix to categorical features"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for filtering cols\n",
        "desired_cols = ['type', 'minplayers', 'maxplayers', 'playingtime', 'minplaytime', 'maxplaytime', 'minage', 'avg_rating', 'bay_rating', 'complexity', 'categories', 'mechanics', 'num_mechs', 'num_cats', 'player_diff']\n",
        "\n",
        "# make dummies and attach to frame for tree model\n",
        "tree_frame = dtc_test[desired_cols]\n",
        "mech_dummies = pd.get_dummies(tree_frame['mechanics'], prefix='mech', drop_first=True)\n",
        "tree_frame = pd.concat([tree_frame, mech_dummies], axis=1)\n",
        "cat_dummies = pd.get_dummies(tree_frame['categories'], prefix='cat', drop_first=True)\n",
        "tree_frame = pd.concat([tree_frame, cat_dummies], axis=1)"
      ]
    },
    {
      "source": [
        "#### filter out categorical columns for tree fitting"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of just desired features, now including one-hot cols and remove categorical cols\n",
        "features = list(tree_frame.columns)\n",
        "\n",
        "# remove categorical cols\n",
        "features.remove('mechanics')\n",
        "features.remove('categories')\n",
        "\n",
        "# remove target cols\n",
        "features.remove('avg_rating')\n",
        "features.remove('bay_rating')\n",
        "\n",
        "# for col in desired_cols:\n",
        "#     features.remove(col)\n",
        "# print(features)"
      ]
    },
    {
      "source": [
        "### Divide the data set\n",
        "#### split data into training portions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtered features with one-hot fixes for categorical columns\n",
        "X = tree_frame[features]\n",
        "\n",
        "# target variable - bays because it's not as dramatic\n",
        "y = tree_frame[['bay_rating']]\n",
        "\n",
        "# Split method, 0.3 == 30% of data saved for testing, choosen randomly from set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "source": [
        "### Train the model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q42-XPJjIyXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "94c92518-3ea7-48e3-999c-762159548e53"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "best_acc = 0\n",
        "for j in range(1, 20):\n",
        "    # Linear Regression Model object\n",
        "    lgm = DecisionTreeClassifier(criterion=\"entropy\", splitter='best', max_depth=19+j)\n",
        "\n",
        "    # Train Decision Tree Classifer\n",
        "    dtc = dtc.fit(X_train,y_train)\n",
        "\n",
        "    # predictions by model for y\n",
        "    y_pred = dtc.predict(X_test)\n",
        "\n",
        "    # custom accuracy check\n",
        "    correct = 0\n",
        "    y_targets = y_test[\"categories\"].tolist() \n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] in y_targets[i]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtc)\n",
        "        best_acc = accuracy\n",
        "        print(\"depth: \", j)\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# SAVE MODEL!! (and test accuracy of accuracy rating)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# swtich to model directory\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\models\")\n",
        "\n",
        "# create and save file\n",
        "joblib_file = \"dtc_all_9041.joblib\"  \n",
        "dump(best_dtc, joblib_file)\n",
        "\n",
        "# test load\n",
        "joblib_model = load(joblib_file)\n",
        "\n",
        "y_pred = joblib_model.predict(X_test)\n",
        "\n",
        "# custom accuracy check\n",
        "correct = 0\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] in y_targets[i]:\n",
        "        correct += 1\n",
        "\n",
        "print(\"Accuracy:\", correct / len(y_pred))"
      ]
    },
    {
      "source": [
        "### visualize training depths"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "max_depth = []\n",
        "acc_gini = []\n",
        "acc_entropy = []\n",
        "\n",
        "best_acc = correct / len(y_pred)\n",
        "best_dtc = dtc\n",
        "\n",
        "y_targets = y_test[\"categories\"].tolist() \n",
        "for i in range(1,36):\n",
        "    # testing entropy\n",
        "    dtree = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_entropy.append(accuracy)\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # testing gini\n",
        "    dtree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=i)\n",
        "    dtree.fit(X_train, y_train)\n",
        "    y_pred = dtree.predict(X_test)\n",
        "    correct = 0\n",
        "    for j in range(len(y_pred)):\n",
        "        if y_pred[j] in y_targets[j]:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / len(y_pred)\n",
        "    acc_gini.append(accuracy)\n",
        "\n",
        "    if accuracy > best_acc:\n",
        "        best_dtc = deepcopy(dtree)\n",
        "        best_acc = accuracy\n",
        "        print(\"best acc: \", accuracy)\n",
        "\n",
        "    # track depth for values\n",
        "    max_depth.append(i)\n",
        "\n",
        "\n",
        "# data frame with tracked values to graph\n",
        "df = pd.DataFrame({'acc_gini':pd.Series(acc_gini), \n",
        "'acc_entropy':pd.Series(acc_entropy),\n",
        "'max_depth':pd.Series(max_depth)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib_file = \"dtc_8936.joblib\"  \n",
        "dump(best_dtc, joblib_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# graph folder\n",
        "os.chdir(r\"C:\\Users\\Zack\\Desktop\\work\\OSU\\406 - p2 - learning\\jupyter practice\\final models\\graphs\")\n",
        "\n",
        "#size \n",
        "sns.set(rc={'figure.figsize': (6, 6)})\n",
        "\n",
        "print(max_depth)\n",
        "# visualizing changes in parameters\n",
        "sns.lineplot(x='max_depth', y='acc_gini', data=df)\n",
        "sns.lineplot(x='max_depth', y='acc_entropy', data=df)\n",
        "plt.xlabel('max depth')\n",
        "plt.ylabel('accuracy')\n",
        "# plt.xlim(1,30)\n",
        "plt.savefig('gini vs entropy', bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "### Visualize training tree model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "# dot_data = StringIO()\n",
        "# # number of unique values in target col\n",
        "# class_names = list(tree_frame.categories.unique())\n",
        "\n",
        "# # use trained decision tree model, feature columns, and clases in target col\n",
        "# export_graphviz(dtc, out_file = dot_data, filled=True, rounded=True, special_characters=True,\n",
        "#                 feature_names = features,\n",
        "#                 class_names = class_names)\n",
        "\n",
        "# # creates image and then displays in Jupyter\n",
        "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "# graph.write_png('game_classes.png')\n",
        "# Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}